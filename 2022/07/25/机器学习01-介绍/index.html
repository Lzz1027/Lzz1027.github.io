<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习01 介绍 | TakuZen&#39;s Blog | Code is Poetry</title>

  
  <meta name="author" content="ZhuoRan-TakuZen">
  

  
  <meta name="description" content="A personal Blog about Machine Learning.">
  

  
  
  <meta name="keywords" content="DeepLearning,MachineLearning">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="机器学习01 介绍"/>

  <meta property="og:site_name" content="TakuZen&#39;s Blog"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="TakuZen&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">TakuZen&#39;s Blog</a>
    </h1>
    <p class="site-description">Code is Poetry</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>机器学习01 介绍</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2022/07/25/机器学习01-介绍/" rel="bookmark">
        <time class="entry-date published" datetime="2022-07-25T12:08:00.000Z">
          2022-07-25
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>台大李宏毅老师机器学习课程学习笔记，暑期重新整理：</p>
<p>近年来 AI 技术越来越热，各种 AI 技术被吹捧的神乎其神，当前的 AI 技术到底发展到了什么程度？又在朝着哪里发展？</p>
<p>事实上目前所说的“AI”与科幻小说中通人情，高智商的强人工智能还相去甚远，大部分都还只是 Machine Learning，是一种“暴力”方式解决问题的技术。</p>
<h2 id="Machine-Learning-≈-Looking-for-Function"><a href="#Machine-Learning-≈-Looking-for-Function" class="headerlink" title="Machine Learning ≈ Looking for Function"></a>Machine Learning ≈ Looking for Function</h2><p>简单来说，机器学习的实质是<strong>寻找一个难以用人力创造的函数</strong></p>
<p>如下图：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314151118633.png" alt="image-20220314151118633"></p>
<p>很多复杂问题都能概括为寻求一个函数，给定输入，以期望得到某个正确的输出。</p>
<ul>
<li>语音识别：给定音频信号，输出对应语言的文字</li>
<li>图像识别：给定图片数据，输出对应事物的名称</li>
<li>围棋AI：给定棋盘数据，得到胜率最高达的下一步坐标</li>
</ul>
<p>但这些问题通常难以解决，特别是涉及高维和低维信息之间转换的问题，难以用传统方法寻求二者之间的联系。</p>
<p>随着计算机算力水平的提升，用机器每秒上百万次的强大运算能力来“暴力破解”输入输出之间的关系也不再是空谈，这就是机器学习。</p>
<h2 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h2><p>简单来说机器学习可以分为以下三类：</p>
<p><strong>Regression（回归）</strong>：让函数得到某个数值。如 PM2.5 预测</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314151404348.png" alt="image-20220314151404348"></p>
<p><strong>Classification（分类）</strong>：给出一些选项（类别），函数输出正确的选项。如垃圾邮件分类</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314151527247.png" alt="image-20220314151527247"></p>
<p> <strong>Structured Learning（结构）</strong>：构建出具有结构的输出。如生成图像，文档</p>
<h2 id="如何获得这个函数？"><a href="#如何获得这个函数？" class="headerlink" title="如何获得这个函数？"></a>如何获得这个函数？</h2><p>函数由表达式、输入和输出组成，第一步就是写出表达式：</p>
<h3 id="1-写出带有未知参数的函数"><a href="#1-写出带有未知参数的函数" class="headerlink" title="1.写出带有未知参数的函数"></a>1.写出带有未知参数的函数</h3><p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314164944251.png" alt="image-20220314164944251"></p>
<p>其中，y是函数结果，x1是输入。</p>
<p>通常而言，我们不表达式都不是上图这种简单的线性方程，具体函数形式基于不同的问题而定，上面的例子中，习惯将w称作权重，b称作偏差。</p>
<p>如何选择合适的表达式，构建出符合问题要求的模型，是当下机器学习领域的重点之一。</p>
<p>不难看出，上述表达式中存在很多未知的参数，这些参数就是要求解部分，得到参数后，对于任意给定的输入均能得到对应输出。</p>
<p>那么参数如何计算得到呢？</p>
<p>要计算参数，可以通过对已知结果逆运算得出，这些已知的“输入”被称为特征，“输出”被称为标记，共同构成了训练数据。</p>
<p>如果有海量的训练数据，就能通过这些数据反推出合适的参数，从而得到最终的表达式。为此需要有一个衡量参数好坏的函数，在每一次使用训练数据计算参数时，对参数进行评估，从而方便下一步对参数进行调整。</p>
<h3 id="2-基于训练数据计算-Loss"><a href="#2-基于训练数据计算-Loss" class="headerlink" title="2.基于训练数据计算 Loss"></a>2.基于训练数据计算 <strong>Loss</strong></h3><p>Loss 是计算结果偏差的函数，用于衡量当前得到的未知参数的好坏。</p>
<p>在第一次计算时，我们可以随机对参数进行赋值，将输入代入表达式，得到预测结果，之后与 <strong>Label（真实数据）</strong> 计算Loss（通常是MAE、MSE等差额计算）。从而反映出本次表达式所使用的的参数的优劣程度。</p>
<p>如果将各种可能的未知参数都尝试一遍，计算出相应的 Loss，绘制出 <strong>”Error Surface“</strong>，可以观测到最合适的未知参数。</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314170218911.png" alt="image-20220314170218911"></p>
<p>但真实情况中，由于参数众多，形式复杂，很难用图像直观表达出来，只能得到不同情况下参数对应的 Loss 值。</p>
<p>在得到 Loss 后，我们就了解了目前的参数的优劣，之后就需要将参数进行调整，使计算结果更加贴近真实值，让 Loss 越来越小，也就是 Optimization（优化） 的过程。</p>
<h3 id="3-优化"><a href="#3-优化" class="headerlink" title="3.优化"></a>3.优化</h3><p>获得最佳的未知参数，可以使用 <em><strong>Gradient Descent（梯度下降）</strong></em> ，单个参数的该算法步骤如下：</p>
<p>首先，随机选取一个 w 作为初始值</p>
<p>其次，计算该 w 对应的 loss 值，并计算 L 在 w 上的微分（即斜率）</p>
<p>​        通过这一步，我们可以确定此时的 w 值是偏大还是偏小，如果斜率为正，说明 w 增加会增大 Loss，w 减少则会减少 Loss，斜率为负值则相反，</p>
<p>之后，我们需要设定一个 <strong>η（学习速率）</strong>，来划定我们每次对 w 的变化大小， 对 w 进行变化（用 η 乘上微分）后反复如上的计算，从而获得最佳的未知参数。这些由我们自己设定的参数被称为 <em><strong>Hyperparameters（超参数）</strong></em></p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314171705030.png" alt="image-20220314171705030"></p>
<p>然而，我们很容易发现，这种方法在微分值为0时就会停止，得到的参数可能只是局部最佳值，而非全局最佳值。不过尽管 Gradient Descent 存在这一问题，但在实际生产实践中可以通过取多次随机点的方式轻松解决，这一方法的真正痛点另有别处。</p>
<p>相应的，多参数方法也很容易得到：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314172110989.png" alt="image-20220314172110989"></p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314172226936.png" alt="image-20220314172226936"></p>
<h2 id="如何改进？"><a href="#如何改进？" class="headerlink" title="如何改进？"></a>如何改进？</h2><p>经过上述的三个基本步骤，我们很容易就能计算出“最佳”的未知参数，但事实上，这种预测往往存在较大偏差，在上述例子中，我们选用的是最简单的 <strong>Liner Model（线性模型）</strong>，即使用权重和偏差值来进行预估的简单模型，这种模型考虑的因素少，性能有限，只能表现线性的单调变化。</p>
<p>实际问题中，我们往往需要更加贴合实际问题的模型，这才是机器学习的难点所在。</p>
<h3 id="Sigmoid-Function（S形函数）"><a href="#Sigmoid-Function（S形函数）" class="headerlink" title="Sigmoid Function（S形函数）"></a>Sigmoid Function（S形函数）</h3><p>由于函数变化多种多样，我们可以将函数分为多段，每一段视为一个斜率近似固定的直线，这样我们就将一条曲线分解为了多段曲线之和，每一段曲线的其他部分均为常数，只有在与其斜率吻合的部分是有斜率的，即下图的 <strong>Hard Sigmoid（硬S函数）</strong></p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314182644869.png" alt="image-20220314182644869"></p>
<p>由于分段函数表达式不便于计算，我们使用 <strong>Sigmoid Function（S形函数）</strong>来近似的表达这些曲线。</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314183750691.png" alt="image-20220314183750691"></p>
<p>其中，w 用于改变斜率，b 用于改变左右位置，c 改变高度</p>
<p>这样我们就能将曲线拆分为多个 Sigmoid Function 之和：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314183859065.png" alt="image-20220314183859065"></p>
<p>将这一程序化过程用线性代数表示即为如下方式：<img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314184826782.png" alt="image-20220314184826782"></p>
<p>将其中的未知参数拼接为向量 θ ：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314185208598.png" alt="image-20220314185208598"></p>
<p>此时，Loss 计算方法不变，仍然是给定一组 θ ，与真实值 label 进行对比即可：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314195756458.png" alt="image-20220314195756458"></p>
<p>参数优化方法也仍然相似：</p>
<p>​	找出初始值（随机）；</p>
<p>​	求参数向量的微分向量（ <em>gradient</em> ）；</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314195956073.png" alt="image-20220314195956073"></p>
<p>​	更新 θ 向量：    </p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314200128627.png" alt="image-20220314200128627"></p>
<p> 重复计算和更新，直到计算结束（无法计算或重复一定次数）</p>
<h3 id="分组（Batch）优化"><a href="#分组（Batch）优化" class="headerlink" title="分组（Batch）优化"></a>分组（Batch）优化</h3><p>之前计算 Loss 时，我们将全部输入与真实值对比得到 Loss，另一种方法是，将整个数据集分为一个个 <strong>Batch</strong>，每个 Batch 大小相同，具体大小随意。</p>
<p>每次对一个组进行 Loss 计算，之后使用这个 Loss 计算 gradient，使用这个 gradient 更新参数向量 θ，再将这个新的 θ 放到 下一个组中计算 Loss，如此重复直到所有的组完成一次计算，这样就对<strong>所有数据完成了一次训练</strong>，即一次 <strong>Epoch</strong>。</p>
<p>在这一次 epoch 中，更新了相当于 batch 数量的 update 次数。</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314202247672.png" alt="image-20220314202247672"></p>
<h3 id="Rectified-Linear-Unit（ReLU函数"><a href="#Rectified-Linear-Unit（ReLU函数" class="headerlink" title="Rectified Linear Unit（ReLU函数)"></a>Rectified Linear Unit（ReLU函数)</h3><p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314202456620.png" alt="image-20220314202456620"></p>
<p>除了 S 形函数外，也可以使用上图所示的 ReLU 函数 ，两个 ReLU 函数相加就能得到一个 S 形函数表示的折线：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314202848249.png" alt="image-20220314202848249"></p>
<p>在列出表达式时需要注意：<img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314202931594.png" alt="image-20220314202931594"></p>
<p>相较于线性模型，使用 ReLU 可以带来较为显著的提升，课程样例的结果如下：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314203137316.png" alt="image-20220314203137316"></p>
<p>可以看到当 ReLU 数量较少时效果一般，但当 ReLU 数量较多时，更加贴合的曲线就能带来更好的预测效果。</p>
<h3 id="“套娃”"><a href="#“套娃”" class="headerlink" title="“套娃”"></a>“套娃”</h3><p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314203526849.png" alt="image-20220314203526849"></p>
<p>我们也可以使用 ReLU 等模型进行反复“套娃处理”，多进行几层，增加更多的参数，进行更相似的拟合，得到更好的预测效果：</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314203800478.png" alt="image-20220314203800478"></p>
<p>经过上述优化，我们得到的曲线如下图蓝色曲线所示，尽管已经非常贴近，但一些意外（如下图拟合失误的部分，正处于除夕，计算机无法预测到这一影响）</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314203951386.png" alt="image-20220314203951386"></p>
<h2 id="神经网络-amp-深度学习"><a href="#神经网络-amp-深度学习" class="headerlink" title="神经网络 &amp; 深度学习"></a>神经网络 &amp; 深度学习</h2><p>由于整个计算过程中有大量的 Sigmoid 或者 ReLU 这样的小单元，就好像一个个神经元一样，我们将每个 Sigmoid 或者 ReLU 称为 <strong>Neuron（神经元）</strong>，整个模型被称为 <strong>Neural Network（神经网络）</strong></p>
<p>像上文提到的<strong>“套娃”</strong>一样，有着多层嵌套结构的机器学习，就称为 <strong>Deep Learning 深度学习</strong></p>
<h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><p>1.既然任何曲线都可用多段的 ReLU 或 Sigmoid 拼接，为什么不使用更多的神经元来模拟，而进行这种增加层数的操作呢？</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314210841598.png" alt="image-20220314210841598"></p>
<p>2.层数越多越好吗？然而现实中，经常出现 <strong>Overfitting（过拟合）</strong>问题，即训练资料上表现好，但在预测中表现不好，那我们该采用多少层的模型呢？又如何解决 Overfitting 问题呢？</p>
<p><img src="https://raw.githubusercontent.com/Lzz1027/markdownImage/main/img/image-20220314211103505.png" alt="image-20220314211103505"></p>
<p>（事实上，大所数有更多层次的模型表现不好的问题根源在于最优解没有找到，由于梯度下降方法往往只能得到局部最优解，所以产生了更差的效果，并非过拟合的情况）</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/Note/">Note</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/DeepLearning/">DeepLearning</a><a href="/tags/MachineLearning/">MachineLearning</a>
    </span>
    

    </div>

    
  </div>
</article>

  

	<section id="comment" class="comment">
		<div id="vcomments"></div>
	</section>
	<!-- LeanCloud -->
	<script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.10.0/dist/av-min.js"></script>
	<!-- Valine -->
	<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
	<script>
		new Valine({
			el: '#vcomments',
			appId: 'FGQ8zuHTdVNgVWaNK9TI1Md9-gzGzoHsz',
			appKey: 'etVGbTl6l7ovK2VGnoOaXSHo'
		})
	</script>






    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2022 ZhuoRan-TakuZen
    
  </p>
</footer>
    
    
  </div>
</div>
</body>
</html>